{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context (c) is the sum of all hidden states multiplied by some Weights $\\alpha$ -> Alpha is calculated with a softmax\n",
    "\n",
    "\n",
    "s is the hidden state of the decoder -> S gets calculated just like a GRU model\n",
    "\n",
    "\n",
    " The outpout y_hat is generated using:\n",
    " - (decoder) Hidden State, \n",
    " - Last Input (last input will be previous prediction in out case)\n",
    " - Context (encoder forward and backward hidden states concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (177682063.py, line 91)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 91\u001b[0;36m\u001b[0m\n\u001b[0;31m    update_gate = torch.sigmoid(torch.mm(self.s_update_gate_Wx, x_t) + torch.mm(self.s_reset_gate_Ws, s) + !! TODO!!)\u001b[0m\n\u001b[0m                                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def init_weights(module: nn.Module):\n",
    "    \"\"\"Initializes a single module depending on its type\"\"\"\n",
    "    for param in module.parameters():\n",
    "        torch.nn.init.xavier_uniform_(param.data)\n",
    "\n",
    "class Attention_RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=1, hidden_size_encoder_h=30, hidden_size_encoder_g=30, decoder_hidden_state_s_length=10, output_size=1):\n",
    "        super(Attention_RNN, self).__init__()\n",
    "        self.hidden_size_encoder_h = hidden_size_encoder_h\n",
    "        self.hidden_size_encoder_g = hidden_size_encoder_g\n",
    "        \n",
    "        # Encoder - Bi directional_rnn\n",
    "        self.encoder_h_Wh = nn.Parameter(torch.FloatTensor(hidden_size_encoder_h, hidden_size_encoder_h))\n",
    "        self.encoder_h_Wx = nn.Parameter(torch.FloatTensor(hidden_size_encoder_h, input_size))\n",
    "        self.encoder_h_bias = nn.Parameter(torch.FloatTensor(hidden_size_encoder_h, 1))\n",
    "        self.encoder_g_Wh = nn.Parameter(torch.FloatTensor(hidden_size_encoder_g, hidden_size_encoder_g))\n",
    "        self.encoder_g_Wx = nn.Parameter(torch.FloatTensor(hidden_size_encoder_g, input_size))\n",
    "        self.encoder_g_bias = nn.Parameter(torch.FloatTensor(hidden_size_encoder_g, 1))\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_hidden_s_length = decoder_hidden_state_s_length\n",
    "\n",
    "        # Decoder - Context Vector Calculation\n",
    "        self.W_a_s = nn.Parameter(torch.FloatTensor(1, decoder_hidden_state_s_length))\n",
    "        self.U_a_enc_annot = nn.Parameter(torch.FloatTensor(1, hidden_size_encoder_h + hidden_size_encoder_g))\n",
    "        self.va_T = nn.Parameter(torch.FloatTensor(1, 1))\n",
    "        \n",
    "        # GRU\n",
    "        self.s_update_gate_Wx = nn.Parameter(torch.FloatTensor(decoder_hidden_state_s_length, input_size))\n",
    "        self.s_update_gate_Ws = nn.Parameter(torch.FloatTensor(decoder_hidden_state_s_length, decoder_hidden_state_s_length))\n",
    "        self.s_update_gate_Wc = nn.Parameter(torch.FloatTensor(decoder_hidden_state_s_length, 1))\n",
    "        \n",
    "        self.s_reset_gate_Wx = nn.Parameter(torch.FloatTensor(decoder_hidden_state_s_length, input_size))\n",
    "        self.s_reset_gate_Ws = nn.Parameter(torch.FloatTensor(decoder_hidden_state_s_length, decoder_hidden_state_s_length))\n",
    "        self.s_reset_gate_Wc = nn.Parameter(torch.FloatTensor(decoder_hidden_state_s_length, 1))\n",
    "\n",
    "        self.s_Wx = nn.Parameter(torch.FloatTensor(decoder_hidden_state_s_length, input_size)) # weights that are multiplied with input\n",
    "        self.s_Ws = nn.Parameter(torch.FloatTensor(decoder_hidden_state_s_length, decoder_hidden_state_s_length)) # weights that are multiplied with s_t-1\n",
    "        self.s_b = nn.Parameter(torch.FloatTensor(decoder_hidden_state_s_length, 1)) # bias for hidden state s\n",
    "\n",
    "        self.output_Ws = nn.Parameter(torch.FloatTensor(output_size, decoder_hidden_state_s_length))\n",
    "        self.output_bias = nn.Parameter(torch.FloatTensor(output_size, 1))\n",
    "        init_weights(self)\n",
    "\n",
    "    def forward(self, input_sequence: list[float], horizon=20):\n",
    "        input_sequence = [torch.tensor([[input]], dtype=torch.float32) for input in input_sequence] # map input values to tensors\n",
    "\n",
    "\n",
    "        # Encoder - BiDir RNN - Forward pass\n",
    "\n",
    "        # Todo: Forward Passes are GRU!\n",
    "        forward_hidden_states = torch.tensor([])\n",
    "        backward_hidden_states = torch.tensor([])\n",
    "\n",
    "        encoder_h = torch.zeros((self.hidden_size_encoder_h, 1))\n",
    "        encoder_g = torch.zeros((self.hidden_size_encoder_g, 1))\n",
    "        for x_t in input_sequence: # compute forward hidden layers\n",
    "            encoder_h = torch.tanh(torch.mm(self.encoder_h_Wx, x_t) + torch.mm(self.encoder_h_Wh, encoder_h) + self.encoder_h_bias)\n",
    "            forward_hidden_states = torch.hstack([forward_hidden_states, encoder_h])\n",
    "\n",
    "        for x_t in reversed(input_sequence): # compute backward hidden layers\n",
    "            encoder_g = torch.tanh(torch.mm(self.encoder_g_Wx, x_t) + torch.mm(self.encoder_g_Wh, encoder_g) + self.encoder_g_bias)\n",
    "            backward_hidden_states = torch.hstack([backward_hidden_states, encoder_g])\n",
    "\n",
    "        encoder_context = torch.vstack([forward_hidden_states, backward_hidden_states])\n",
    "        \n",
    "        # Decoder \n",
    "        outputs = torch.tensor([])\n",
    "        s = torch.zeros((self.decoder_hidden_s_length, 1)) # No! Use computation from paper for inital s state: s0 = tanh (Wsh1 ,whereWsâˆˆR) .\n",
    "        \n",
    "        for i in range(horizon):\n",
    "            if i == 0:\n",
    "                x_t = input_sequence[-1] # for t=1 take last element of sequence as input, \n",
    "            else:\n",
    "                x_t = torch.tensor([[outputs[0][-1]]]) # after first run we will use the output of t as input for t+1\n",
    "            scores = torch.tensor([])\n",
    "            \n",
    "            for column_idx in range(encoder_context.shape[1]):\n",
    "                encoder_column = encoder_context[:,column_idx].view(self.hidden_size_encoder_g + self.hidden_size_encoder_h, 1)\n",
    "                test_s = torch.tanh(torch.mm(self.W_a_s, s))\n",
    "                test_h = torch.tanh(torch.mm(self.U_a_enc_annot, encoder_column))\n",
    "                enc = self.va_T * (test_s + test_h)\n",
    "                scores = torch.hstack((scores, enc))\n",
    "            scores = scores.view(-1) # reduce dimensionality to an array of length of input_sequence\n",
    "\n",
    "            alpha = torch.exp(scores) / torch.sum(torch.exp(scores)) # compute soft alignment via softmax\n",
    "\n",
    "            context_vector = alpha * torch.sum(encoder_context, dim=0) # column wise sum of encoder hidden states, elementwise multiplied with the soft aligment (alpha)\n",
    "\n",
    "            update_gate = torch.sigmoid(torch.mm(self.s_update_gate_Wx, x_t) + torch.mm(self.s_reset_gate_Ws, s) + !! TODO!!)\n",
    "            reset_gate = torch.sigmoid(torch.mm(self.s_reset_gate_Wx, x_t) + torch.mm(self.s_reset_gate_Ws, s) + !! TODO -- torch.mm(self.s_reset_gate_Wc, context_vector)) # how do i include the context vector here?\n",
    "\n",
    "            s_hat = torch.tanh(torch.mm(self.s_Wx, x_t) + torch.mm(self.s_Ws, reset_gate * s) + self.s_b)\n",
    "            s = (1 - update_gate) * s + update_gate * s_hat\n",
    "\n",
    "            output = torch.mm(self.output_Ws, s) + self.output_bias\n",
    "            outputs = torch.hstack([outputs, output])\n",
    "\n",
    "        # TODO:\n",
    "        # - Context Vector einbauen!\n",
    "        \n",
    "        return outputs\n",
    "rnn = Attention_RNN()\n",
    "res = rnn.forward([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.90601495  1.63867351 -1.47113026  1.33913807 -0.0960888  -1.86554678\n",
      " -1.15236933 -0.32852723  1.53189361  2.01740418 -1.47527157 -0.91008446\n",
      " -0.33660687  1.53313289  0.65655206 -0.02461345  0.61042546  0.10423771\n",
      " -1.94875334  0.55574617]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given information\n",
    "T_x = 5  # Length of input sequence\n",
    "h_j = np.random.randn(T_x, 20)  # Example annotations\n",
    "s_i_minus_1 = np.random.randn(20)  # Example previous hidden state\n",
    "\n",
    "# Step 1: Compute Alignment Scores\n",
    "e_ij = np.dot(h_j, s_i_minus_1)  # Example, you might use your alignment model here\n",
    "\n",
    "# Step 2: Convert Scores to Probabilities (Softmax)\n",
    "alpha_ij = np.exp(e_ij) / np.sum(np.exp(e_ij))\n",
    "\n",
    "# Step 3: Compute Context Vector\n",
    "c_i = np.dot(alpha_ij, h_j)\n",
    "\n",
    "# c_i is now the context vector for the current target word\n",
    "print(c_i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alignment model makes every column (every encoder hidden state) to 1 scalar value.\n",
    "So we need to do a another linear transformation - we should have an array of values with the length of the sequence.\n",
    "\n",
    "Then we have eg 5 values and compute the softmax for each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.39122158, -0.35900938, -0.02724631,  0.99284855, -0.54483422,\n",
       "        -0.4454687 ,  1.05830879,  0.18275135, -0.57850272, -1.30729521,\n",
       "        -1.40520216, -0.62124035,  0.06086983, -0.76725387,  0.65492017,\n",
       "        -0.97496826, -1.46493554,  2.0951481 , -2.06958731,  1.63479271],\n",
       "       [-0.24591995, -1.03656163, -1.23235428, -1.65390963, -0.70743348,\n",
       "        -1.22892547,  0.16049599,  1.25423442, -0.04845718, -1.63890873,\n",
       "         0.39184552,  0.9025752 ,  0.72913689, -0.7562229 , -0.2987512 ,\n",
       "        -0.03213972, -0.01735861,  0.45435268, -0.60665298, -0.81922412],\n",
       "       [ 1.90647258,  1.64018429, -1.47225074,  1.33943024, -0.09575999,\n",
       "        -1.86665818, -1.15402338, -0.32892218,  1.53350443,  2.01991328,\n",
       "        -1.47535611, -0.91032865, -0.33689583,  1.53485998,  0.65655237,\n",
       "        -0.02390761,  0.61196465,  0.10276552, -1.94869079,  0.55495783],\n",
       "       [-1.30503722, -1.21921882,  0.57068719, -0.80024686,  0.43679601,\n",
       "        -0.20774427, -0.88725707, -0.014516  , -0.52112779,  0.65908076,\n",
       "         0.91217314,  0.60745206, -0.13741113,  0.97444701,  1.49939032,\n",
       "         0.12401548,  0.47902588,  0.34085181,  0.15453434,  0.65978184],\n",
       "       [-1.49023113,  0.77255271,  0.84532175, -0.02776035, -0.07420341,\n",
       "         1.08790886, -0.24217966,  0.52611556, -0.58996247, -0.28895079,\n",
       "        -0.37499317,  0.3517954 , -0.72301291,  0.33437628,  0.41767916,\n",
       "        -0.19881912,  0.5182334 , -0.10346162, -1.08761269, -0.11274373]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights (alpha_ij): [0.2 0.1 0.5 0.2]\n",
      "\n",
      "Annotation Vectors (h_j):\n",
      "[[ 0.26796207  2.14448422]\n",
      " [ 1.50859956  0.80246791]\n",
      " [ 0.36710484 -1.38135004]\n",
      " [ 0.13026343 -0.14947087]]\n",
      "\n",
      "Context Vector (c_i): [ 0.41405748 -0.21142556]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example dimensions\n",
    "T_x = 4  # Length of the input sequence\n",
    "d_h = 2  # Dimensionality of annotation vectors and context vector\n",
    "\n",
    "# Example values (randomly generated for illustration)\n",
    "alpha_ij = np.array([0.2, 0.1, 0.5, 0.2])  # Attention weights\n",
    "h_j = np.random.randn(T_x, d_h)  # Annotation vectors\n",
    "\n",
    "# Calculate context vector\n",
    "c_i = np.dot(alpha_ij, h_j)\n",
    "\n",
    "# Display the results\n",
    "print(\"Attention Weights (alpha_ij):\", alpha_ij)\n",
    "print(\"\\nAnnotation Vectors (h_j):\")\n",
    "print(h_j)\n",
    "print(\"\\nContext Vector (c_i):\", c_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.device'>\n",
      "Moved Base_RNN to MPS Device\n",
      "Training Epoch 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobias/miniconda3/envs/ai/lib/python3.11/site-packages/torch/autograd/__init__.py:251: UserWarning: The operator 'aten::sgn.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1699448804225/work/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating Epoch 1...\n",
      "Training Epoch 2... 250. Avg Training Loss: 0.258283 ; Avg Val Loss: 0.234961\n",
      "Validating Epoch 2...\n",
      "Training Epoch 3... 250. Avg Training Loss: 0.240302 ; Avg Val Loss: 0.214327\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/tobias/Documents/FH/3. Semester/DMML/RNN/UÌˆbung/Abgabe/attention.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tobias/Documents/FH/3.%20Semester/DMML/RNN/U%CC%88bung/Abgabe/attention.ipynb#X11sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m model, mps_dev \u001b[39m=\u001b[39m move_to_apple_silicon(base_model)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tobias/Documents/FH/3.%20Semester/DMML/RNN/U%CC%88bung/Abgabe/attention.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m adam_gru \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(base_model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m3e-4\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/tobias/Documents/FH/3.%20Semester/DMML/RNN/U%CC%88bung/Abgabe/attention.ipynb#X11sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m train(base_model, EPOCHS, X_train, y_train, loss_f\u001b[39m=\u001b[39;49mmae_loss, optimizer\u001b[39m=\u001b[39;49madam_gru, device\u001b[39m=\u001b[39;49mmps_dev)\n",
      "File \u001b[0;32m~/Documents/FH/3. Semester/DMML/RNN/UÌˆbung/Abgabe/pipeline.py:72\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(rnn, epochs, training_data, training_labels, loss_f, optimizer, post_epoch_callbacks, validation_split_size, random_seed, plot_loss, horizon, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m label_series \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(label_series)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     71\u001b[0m rnn\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 72\u001b[0m outputs \u001b[39m=\u001b[39m rnn\u001b[39m.\u001b[39;49mforward(data_series, horizon\u001b[39m=\u001b[39;49mhorizon, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m     73\u001b[0m loss \u001b[39m=\u001b[39m loss_f(outputs, label_series) \n\u001b[1;32m     74\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/FH/3. Semester/DMML/RNN/UÌˆbung/Abgabe/models.py:35\u001b[0m, in \u001b[0;36mBase_RNN.forward\u001b[0;34m(self, input_sequence, horizon, device)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(x):\n\u001b[1;32m     34\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(x)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 35\u001b[0m xh \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mvstack([x, hidden])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     36\u001b[0m hidden \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtanh(torch\u001b[39m.\u001b[39mmatmul(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mV, xh) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb)\n\u001b[1;32m     37\u001b[0m outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhstack([outputs, torch\u001b[39m.\u001b[39mmatmul(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW, hidden) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models import Base_RNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pipeline import train, evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data_generation import generate_longterm_data\n",
    "\n",
    "NUM_SEQ = 1000\n",
    "HORIZON=20\n",
    "data_set, labels = generate_longterm_data(NUM_SEQ, variable_steps=False, noise=True, horizon=HORIZON)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_set, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "basic_model = Base_RNN(1,30,1)\n",
    "mse_loss = nn.MSELoss()\n",
    "mae_loss = nn.L1Loss()\n",
    "adam = torch.optim.Adam(basic_model.parameters(), lr=3e-4)\n",
    "EPOCHS = 250\n",
    "\n",
    "def move_to_apple_silicon(model: nn.Module) -> (nn.Module, torch.device):\n",
    "    \"\"\"If exists, move the model to Apple Neural Engine (sort of like cuda, but for apple devices)\"\"\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        mps_device = torch.device(\"mps\")\n",
    "        print(type(mps_device))\n",
    "        print(f\"Moved {model.__class__.__name__} to MPS Device\")\n",
    "        return model.to(mps_device), mps_device\n",
    "    else:\n",
    "        print(\"MPS device not found.\")\n",
    "        return model, None\n",
    "\n",
    "\n",
    "base_model = Base_RNN(1,30,1)\n",
    "model, mps_dev = move_to_apple_silicon(base_model)\n",
    "adam_gru = torch.optim.Adam(base_model.parameters(), lr=3e-4)\n",
    "\n",
    "train(base_model, EPOCHS, X_train, y_train, loss_f=mae_loss, optimizer=adam_gru, device=mps_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
